{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.spatial.distance import cdist\n",
    "import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/MNIST/data_all.npz')\n",
    "trainv = data['trainv']\n",
    "testv = data['testv']\n",
    "trainlab = data['trainlab']\n",
    "testlab = data['testlab']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(train_vec, train_lab, test_vec):\n",
    "    # Compute Euclidean distances\n",
    "    distances = cdist(test_vec, train_vec,metric='euclidean')\n",
    "    # Find the nearest neighbor\n",
    "    nearest_idx = np.argmin(distances,axis=1)\n",
    "    return train_lab[nearest_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction ran for 4m 44.9s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_tests = testv.shape[0]\n",
    "predictions = []\n",
    "for i in tqdm.tqdm(range(int(total_tests/1000))):\n",
    "    test_batch = testv[i*1000:(i+1)*1000]\n",
    "\n",
    "    batch_pred = predict(trainv, trainlab, test_batch)\n",
    "\n",
    "    predictions.append(batch_pred)\n",
    "\n",
    "predictions = np.concatenate(predictions)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to file\n",
    "with open('predictions/mnist_NN_predictions.pkl', 'wb') as f:\n",
    "    pickle.dump(predictions, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "with open('predictions/mnist_NN_predictions.pkl', 'rb') as f:\n",
    "    predictions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if predictions.shape != testlab.shape:\n",
    "    assert(\"shapes dont match\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = np.zeros((10,10),dtype=int)\n",
    "for i in range(predictions.shape[0]):\n",
    "    conf_matrix[testlab[i],predictions[i]] += 1\n",
    "\n",
    "\n",
    "labels = np.arange(10).astype(str)\n",
    "\n",
    "total_sum = np.sum(conf_matrix)\n",
    "diag_sum = np.trace(conf_matrix)\n",
    "err_rate = round((total_sum-diag_sum)/total_sum,4)*100\n",
    "\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "# True Positives: diagonal\n",
    "true_positives = np.diag(conf_matrix)\n",
    "\n",
    "# Total samples per class (sum of rows)\n",
    "class_totals = np.sum(conf_matrix, axis=1)\n",
    "\n",
    "# Avoid division by zero\n",
    "class_accuracy = np.divide(true_positives, class_totals, out=np.zeros_like(true_positives, dtype=float), where=class_totals!=0)\n",
    "\n",
    "# Convert to percentage\n",
    "class_accuracy_percent = np.round(class_accuracy * 100, 2)\n",
    "class_error_percent = 100 - class_accuracy_percent\n",
    "\n",
    "# Shifted matrix for log color\n",
    "conf_matrix_safe = conf_matrix + 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 5), gridspec_kw={'width_ratios': [3, 1]})\n",
    "\n",
    "# Plot confusion Matrix\n",
    "sns.heatmap(conf_matrix_safe, annot=conf_matrix, fmt='d',\n",
    "            cmap='Blues', norm=LogNorm(vmin=1, vmax=conf_matrix_safe.max()),\n",
    "            xticklabels=labels, yticklabels=labels, ax=ax[0])\n",
    "\n",
    "ax[0].set_xlabel(\"Predicted Number\", fontsize=12)\n",
    "ax[0].set_ylabel(\"True Number\", fontsize=12)\n",
    "ax[0].set_title(f\"Confusion Matrix\\nError Rate: {err_rate}%\", fontsize=13)\n",
    "\n",
    "# Bar Plot: Accuracy per class\n",
    "ax[1].barh(labels, class_accuracy_percent, color='mediumseagreen', label='Correct')\n",
    "ax[1].barh(labels, class_error_percent, left=class_accuracy_percent, color='salmon', label='Incorrect')\n",
    "\n",
    "ax[1].set_xlim(0, 100)\n",
    "ax[1].set_xlabel(\"Classification %\")\n",
    "ax[1].set_title(\"Per-Class Accuracy\")\n",
    "ax[1].legend(loc='upper left')\n",
    "ax[1].invert_yaxis()  \n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate correct and incorrect predictions\n",
    "wrong_idx = []\n",
    "correct_idx = []\n",
    "for i in range(predictions.shape[0]):\n",
    "    if predictions[i] != testlab[i]:\n",
    "        wrong_idx.append(i)\n",
    "    else:\n",
    "        correct_idx.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    im_idx = wrong_idx[i]\n",
    "\n",
    "    print(f\"Predicted = {predictions[im_idx]}, True label = {testlab[im_idx]}\")\n",
    "    x = testv[im_idx, :].reshape((28, 28))\n",
    "    plt.imshow(x, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    im_idx = correct_idx[i]\n",
    "\n",
    "    print(f\"Predicted = {predictions[im_idx]}, True label = {testlab[im_idx]}\")\n",
    "    x = testv[im_idx, :].reshape((28, 28))\n",
    "    plt.imshow(x, cmap=\"gray\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ttt4275",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
